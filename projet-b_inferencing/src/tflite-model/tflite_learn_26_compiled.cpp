/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 14.12.2023 09:46:12

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#elif defined __ICCARM__
#define ALIGN(x) __attribute__((aligned(x)))
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 8
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 13280;
#else
constexpr int kTensorArenaSize = 12256;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_CONV_2D, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[7];

const TfArray<4, int> tensor_dimension0 = { 4, { 1,32,32,3 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0039215688593685627, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(8) int32_t tensor_data1[2] = { -1, 1024, };
const TfArray<1, int> tensor_dimension1 = { 1, { 2 } };
const ALIGN(8) int32_t tensor_data2[3] = { 636, -348, -834, };
const TfArray<1, int> tensor_dimension2 = { 1, { 3 } };
const TfArray<1, float> quant2_scale = { 1, { 2.5145211566268699e-06, } };
const TfArray<1, int> quant2_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant2 = { (TfLiteFloatArray*)&quant2_scale, (TfLiteIntArray*)&quant2_zero, 0 };
const ALIGN(16) int8_t tensor_data3[3*1024] = { 
  52, -17, 75, -102, -33, 44, 34, -73, -92, 48, 50, -20, 30, -85, -2, 3, -45, -100, 18, 6, -81, 89, 53, 11, -84, -92, 50, -45, -94, -55, 3, -113, 9, -17, -74, -63, 42, -74, -120, 68, -64, -89, 47, 50, 42, -37, 30, -87, 32, 6, -64, -105, -2, -57, -24, 19, 4, -105, 72, -68, -27, 28, -50, -92, 40, 41, -21, 68, -56, 63, -15, -70, -85, 7, -72, 73, -67, 23, 40, 36, -14, -61, 65, 12, 75, -32, 47, -14, -76, 71, -19, -10, -3, 65, 67, -60, -9, -29, 41, 62, -47, 78, -41, 42, 28, -69, 2, -6, -7, 77, -18, 23, 26, 76, -9, -56, 21, 12, -81, 25, 60, -49, 43, -84, -60, 3, 49, -76, 64, -65, -65, 41, 58, -79, -45, -16, 71, -103, 57, 29, -44, 44, -26, -87, -21, 50, -58, 8, 42, -7, 44, -52, -31, -106, -6, 6, 65, -83, 29, -60, 90, -80, -67, 63, -45, 45, -29, -11, -4, -23, -29, 47, 17, 6, 44, -16, -51, -5, 84, 58, 43, -58, -39, -8, 11, 42, 5, 17, -93, 5, 76, -64, 76, 118, -33, 80, 12, 11, 35, 69, -23, 61, 45, -15, 73, -66, 63, 55, -26, -71, -55, 107, 71, -72, -82, 1, 83, 0, -4, 0, -10, -27, 57, 56, -87, 15, -1, 47, 38, -5, 38, -35, 62, 53, -35, -2, -22, 62, -59, 18, -13, 46, -89, -7, 82, -64, -73, 55, -35, -32, -62, 66, 68, 82, -15, 35, 2, -50, 61, 60, -92, -62, -15, 7, -84, 16, 60, 62, 38, 2, -28, 17, -56, -90, 33, -37, -61, -68, 19, -65, -63, -108, -61, -50, 6, 55, -110, 24, -73, 21, 66, -84, -82, -60, -5, 63, 23, -76, -21, -9, -4, 90, 49, 8, -57, -34, 58, 55, -119, 61, 44, 57, -18, 93, -30, -82, 56, 54, 19, -42, 76, -79, 47, 67, 22, 50, -11, 86, 6, -61, 7, -115, 81, 10, 37, -60, -94, 66, -86, 110, -87, -19, 90, 48, 81, -40, -53, 10, 71, -25, 76, -56, -66, -31, -79, -72, 36, -47, -5, 60, -20, -38, -17, -3, 5, -71, -3, 107, -49, 14, 36, 47, 66, 73, -42, 32, -3, 34, -66, 61, -87, 28, -31, -42, -59, -46, 15, -13, -108, -39, -55, -50, -21, -16, -20, -24, -22, -28, -69, 25, 48, 9, -78, -70, -26, -67, -96, 53, 4, -2, -69, -63, 10, 20, -3, 31, 85, 27, 0, 7, -72, 80, 112, 67, -78, 84, 91, -24, -31, -29, 105, 60, 3, -10, -79, -25, 59, -64, 26, 49, 38, 38, -52, -103, 35, -17, 2, -41, -65, -1, -19, 62, 30, -51, 51, -53, -78, 77, -2, -11, -43, 24, 13, 43, 56, 1, -5, 25, -10, -4, 30, -13, -37, 1, 63, -73, 37, 33, 101, 77, 33, 107, -41, -8, -66, -75, -1, -9, -71, -37, 49, 82, -22, 87, -54, 6, -55, -41, -79, 67, 78, -40, 73, 21, -75, -75, 71, -62, 40, 56, 32, -28, -78, 4, 38, -21, -35, 55, -35, 41, -4, -102, 45, 52, 31, 3, -18, -7, 39, 86, -15, -24, 68, -37, 28, 66, -56, -17, -62, -19, -70, 60, 13, -4, -25, 29, 52, 101, -28, 53, -33, 39, -31, 50, -67, 66, -18, 52, 16, 28, -76, 97, -55, 3, 33, -11, 101, 45, 12, -32, -39, -62, 82, 38, -20, 66, -5, -58, -90, 55, 47, 13, 52, 65, -2, 5, -12, 42, 46, -86, -1, 22, 0, 76, 39, -70, -49, 8, 9, -80, 57, -60, -39, -55, -62, -39, 9, 93, 78, 43, 1, 67, 12, 51, 37, -72, 33, -34, 21, 68, -28, 64, -75, 31, 75, 40, -59, -2, 49, -23, 44, 35, -92, 47, -10, -17, 38, -34, 52, 30, -16, -68, -69, -23, 24, 87, -110, 30, 61, -91, -23, 27, -51, -76, -94, -42, 10, 34, -50, -77, 37, -64, -44, -32, -23, -85, 30, 35, -65, -88, -11, 14, 80, 94, 6, 38, 38, -1, -14, -48, -78, 19, 56, -95, 50, -11, 2, -21, -67, -66, 49, 89, -37, -48, -62, -40, -26, 20, 67, -76, -39, -71, -25, -51, 59, 45, 91, -48, -9, 17, -23, -75, 23, -37, 1, -67, -57, -70, -17, -57, -68, -11, -42, -19, 1, -78, -55, 62, 57, -87, -89, -33, -15, -81, 73, -60, -1, -68, 65, -48, 13, -41, -69, -26, 62, 25, 98, -29, -113, 48, 6, -71, -48, 54, -20, -22, -3, 18, -57, 17, 10, 16, -68, 12, -27, -11, 0, 10, -51, -84, -39, 37, -108, 52, -11, -86, 7, -20, -48, -61, -52, -13, -30, 7, 75, -44, 12, -46, -23, 59, -76, 18, 7, -26, 34, -64, -38, -66, -21, -90, 28, 57, -2, 5, -69, 68, -110, -14, 73, 70, 38, -12, -36, 84, -71, 41, 76, -41, -67, 30, -13, 61, -23, 41, 72, -61, 77, -43, -13, -37, 12, -6, -9, 73, 3, 6, -68, -85, 0, 51, -1, -59, 40, -64, -57, -76, 68, 48, 76, -10, -28, -83, -75, -80, -11, -74, 33, 32, -87, -24, -77, 4, -71, -58, 86, 58, -95, 30, -77, 33, -51, 82, -20, 67, -73, -39, 47, -58, -5, -9, -24, -33, -47, 61, -6, 62, 59, 36, -59, 99, 68, -66, 4, 43, -69, -2, -64, 43, -77, -1, -86, 69, -92, 74, 11, 19, -61, -10, -64, 85, 25, 9, -86, -31, -61, 28, -97, 33, -7, -80, 74, -19, 87, -81, -27, 58, -86, -98, 51, -44, -80, 27, -49, -27, 13, 56, -93, 59, 12, 22, 57, 75, 36, 66, 27, -87, -93, -55, -13, 42, -93, -39, -35, -49, -9, 27, -91, -35, 12, 86, 10, 47, 11, -29, -82, -1, 13, -67, 42, 45, -44, -17, 65, -8, -3, -36, 37, 5, 31, 42, -120, -70, -87, 44, -72, -32, 74, 32, -93, 68, 3, -58, 0, 24, -10, 58, -34, 11, -68, 73, 57, 8, 58, 49, 41, 85, -44, -51, 29, -44, -82, 27, 22, -77, -94, 13, 42, 54, -30, -24, 13, 8, -75, 51, 
  58, 77, -8, -24, -73, 7, 56, -61, 19, 9, -18, 28, 23, 43, 19, 66, 63, 90, -45, 55, 53, -18, 44, -21, 43, 18, 101, 58, 6, -64, 89, -25, 73, 53, -49, -55, 88, -89, -38, 30, 38, -12, -70, -72, -42, -62, -16, 75, 4, 7, -22, 2, 25, 10, -19, -11, -11, 10, -66, -55, 62, 68, -27, 21, 56, 38, 24, 30, 77, 16, 87, 38, -2, 58, 20, 66, 33, 50, -57, -56, -45, -14, -10, -36, 56, 51, -12, 69, 92, 17, -40, 34, -40, 81, -53, 26, -59, -16, 58, 55, -60, -52, -84, -33, -6, -31, -80, 6, -56, -19, -48, 81, -66, -5, 63, 42, 56, 31, 53, 39, -17, 62, -66, -105, 24, 5, -16, -70, -64, 78, -38, 34, -28, -19, 6, -79, -53, -36, -53, -3, 106, -73, 83, 37, -52, 41, 94, 51, -20, 14, 36, -31, -6, 39, -30, -17, -59, -8, 4, 106, 5, 66, -20, 41, 82, -38, 92, -46, -61, 56, -70, 31, 66, -69, 62, -5, 52, -77, 15, 52, -12, 79, 55, -11, 15, 47, 34, -90, -53, 25, -67, 64, -21, -77, -25, -64, 121, -51, -58, 85, -35, -52, 34, 50, -16, -3, -6, -59, 72, -100, -70, -21, 8, -45, -98, -16, -25, 89, -22, 22, -8, 34, -66, 63, -56, 47, 8, 59, 26, -15, 54, -50, 95, 24, 35, 47, 68, -62, 45, -70, -11, 52, 58, 73, -10, -28, 51, 72, -56, -66, 69, 82, 67, -3, -50, -104, 60, -21, -78, -5, -54, -91, 23, 48, 39, 43, -66, 47, -50, -67, 58, 67, -5, 72, -22, -10, 88, -75, -27, -82, 58, 102, 8, -19, -14, 15, -9, -86, 29, -65, 50, -76, -33, -37, -74, -10, 4, -75, 42, -51, -27, -89, -54, 21, 7, 22, -73, -113, 40, -42, -63, -73, 19, 19, -18, 79, -110, -84, -117, 58, 24, 39, -65, 51, 54, 33, -3, -4, 22, 62, -48, -22, -92, -76, -35, -23, 26, -83, 89, -115, -43, -11, -30, 63, -23, -18, 17, 53, -122, -83, -1, -31, -9, 21, 92, 28, 105, 84, -35, -14, -54, -4, -77, -45, 42, 17, 33, 47, -53, -36, 55, 60, -56, -43, -111, -37, 63, 7, -77, -7, -59, 50, 77, 1, -6, 87, -41, 14, 25, -68, 21, -85, -9, 2, -24, -81, 75, -56, 121, -20, -76, -74, 64, -69, 115, -77, 80, -11, 72, 104, -35, 41, 53, 59, 31, -31, -72, -111, -59, 1, -37, -68, -14, 60, 35, 57, 63, 12, -8, -8, 1, -90, -35, 17, 13, -59, 27, -17, -101, 97, 33, -65, -50, 14, -2, -30, -127, -62, -23, 23, -29, -13, -70, -21, -114, -36, -47, -32, 73, -72, -7, -41, -49, -101, 26, -9, 13, 48, 20, 76, -96, 0, 78, 52, -85, -10, -29, 84, -22, 35, -2, -90, 14, -81, -79, -38, -53, -18, -23, 27, -45, -3, 2, -15, 27, 8, -53, -7, -45, -60, 77, -5, 32, -48, 10, -50, 10, 35, -3, -43, 100, 0, -4, 113, -52, 23, 10, 65, -44, 72, -75, 80, 3, -86, 33, 6, -31, -14, -5, -81, -10, 43, 14, -39, 20, 62, -24, 4, 75, -95, 102, 34, 125, 58, -77, -4, -51, -100, 33, -49, 15, 64, 11, 89, -2, -31, -66, 3, -62, 55, 44, 35, 56, -70, -10, 62, 18, 78, 18, 82, -31, 74, 4, -6, -119, -93, -49, -16, -22, -50, -53, -19, -59, -16, 12, -59, -58, -95, 2, 39, 63, 3, -62, 17, -54, -38, -106, 25, -45, -71, 78, 76, 58, 50, -64, 32, -77, -4, 34, -22, 44, -57, 52, -62, 67, -90, -19, 18, -101, 42, -65, -63, -81, -15, -67, 47, -24, 1, 75, 10, -5, 61, -52, -32, -35, -11, -73, 35, -2, 46, 68, -39, 62, -34, 14, -61, 62, -79, 57, 89, -65, -77, 63, -40, 45, -5, -24, -38, 82, 69, 57, 12, 42, -4, -25, 99, -20, -22, 105, -14, 89, 91, -91, 53, -21, -50, 61, -38, -61, 72, 23, -13, -23, -46, 51, -60, -45, -5, 52, -47, 22, -81, -43, -82, 10, -29, -60, -47, -54, -9, -19, -58, 26, -48, -96, -13, 18, 21, 60, -21, -52, -13, 10, 91, -54, -110, -41, -82, 68, -37, -87, -46, -103, 7, 80, 37, 88, 20, 48, -19, -34, 50, 50, -61, 32, -14, 78, 0, -44, -93, 67, 10, 81, 85, -52, 14, -40, -73, -64, -40, 58, -71, 41, 69, 32, -62, 48, -37, -60, -58, 70, 39, 32, 1, -15, -56, 98, 88, 10, -18, 30, -63, 52, 81, 11, 30, -80, -53, 12, -20, 79, -26, -21, 83, 30, 32, -38, 16, 115, 83, 25, 45, 79, 69, -90, 22, 34, -4, -24, -58, -45, 71, -56, -13, 10, -38, 26, -44, 23, -75, 39, -16, -61, -56, -19, 13, 83, 75, 34, -85, -58, -64, 3, -10, 58, 76, 25, -56, 13, -73, 15, 74, -15, -77, -60, -40, -7, -9, -28, -52, -5, 59, 61, 74, 42, 43, 60, 35, -67, 55, -4, 21, 8, -47, -57, -81, -18, 27, -88, 67, 101, 84, 8, 45, 62, 81, 39, 4, -27, -74, 0, 85, 33, -87, -44, 13, 64, 71, -21, -85, 86, 49, 4, -31, 77, -68, -70, 52, 69, 21, -83, 15, -49, -40, -38, 39, -67, -2, 78, 23, 105, -73, 67, -55, 44, -21, 30, 66, 68, 84, -10, -20, -46, 10, 27, -97, 55, 66, 97, 16, -23, -37, 8, 82, 70, -4, 45, 64, 1, -14, -47, -15, 86, 41, 26, 28, 7, -28, 22, 57, -64, -20, 5, -72, 21, 0, -26, 42, 60, -22, 11, -10, 86, 50, -84, 41, -48, -84, 70, 89, 49, 77, -3, 35, -2, 82, 44, 13, -54, 47, -31, -62, 54, 33, -55, -32, 84, -9, 91, 65, 86, 13, 47, -25, -43, -63, -81, 59, 108, 37, 79, -76, 91, -67, 83, -66, 92, 25, 71, -40, 65, -65, -74, 27, 1, 45, 21, 16, 82, -80, -69, -58, -65, 9, -70, -86, 20, 26, -41, -75, -66, 11, 87, -60, 
  -83, -39, 81, -32, -87, -73, -103, -48, 71, -1, 77, -66, -66, 67, -36, 7, 3, -26, -6, 53, 58, 46, 11, -83, -101, 70, 14, 67, 25, 17, -23, -3, -69, -14, 58, 43, -1, 28, 60, 38, -7, -91, -15, 68, 37, 27, -19, -83, -10, -79, -11, 4, 27, -69, -58, 21, 12, 68, 51, 39, 7, -87, -53, 14, 49, 61, 7, -10, -18, -76, -27, 27, -66, -62, -89, 2, 64, 64, -74, -98, -63, -22, 80, -80, -73, -95, -70, -8, -8, 72, -80, -21, 27, 21, -29, 7, -64, -28, -10, 44, -19, 79, 32, -1, 78, -50, -91, -21, -19, -47, 34, 54, -80, -95, 85, -107, -55, 81, 87, 13, 52, -85, 7, -41, -83, -31, -87, -77, 25, -15, 4, -71, 22, -25, 30, -28, -68, -16, -89, 24, 50, -19, -42, -59, -36, -67, 64, 49, -8, -10, 51, -94, -58, 69, 44, -21, -102, -1, -62, -66, 38, 31, 18, 24, -75, 27, 28, -22, 51, -91, -20, -6, -15, -57, -76, 48, 39, -66, 37, 1, -70, -59, 52, 63, -61, -51, -22, 33, 75, 22, 58, 57, 69, -58, 27, -34, 82, 51, 93, 68, 44, 44, -12, -13, -24, 22, -19, -20, -54, -17, 82, -70, -53, 76, 45, -71, 33, -37, -38, 3, 73, 48, 10, -73, -23, -2, 51, -37, -110, -1, -52, -51, 70, -86, 79, 92, -37, -6, -66, 19, 0, 78, -85, -17, 23, 27, 36, -75, 104, 77, 56, 56, 0, -80, -57, 39, -56, 9, 14, -1, 37, 65, -91, 48, -30, 64, -73, 20, -56, -90, -31, -116, -19, 27, 13, -36, -54, 33, -9, -81, -68, -23, 40, -43, -18, -77, -21, 71, -40, 75, -75, -16, -73, -103, -9, 62, -27, -56, 10, -110, -47, 72, -64, 81, 50, -14, -57, 0, -55, 23, 22, 60, 62, -50, -77, -61, -54, 20, 62, 53, -14, 94, -6, -89, -8, -73, -20, 37, 25, 79, -54, -48, 61, -33, 4, 121, 50, -24, -13, -28, 49, -20, -24, 65, -73, -64, 38, -5, 80, 26, 29, 86, 37, 13, 74, -33, 43, 54, 97, -34, -47, -45, 58, -7, 36, 69, -84, -109, 69, 88, 71, -87, 1, 44, 32, 55, 23, 14, -7, 92, -23, 66, -49, 80, -91, 7, -29, -18, -57, -80, -57, -56, -49, 42, -2, -16, 54, -44, 8, -8, -86, 32, -61, 70, 33, -25, -52, -6, -35, 47, -42, -108, -56, 58, 49, 104, -4, 55, -1, 12, -3, 72, -25, -63, -77, -94, 59, -88, -59, -62, -59, -60, 67, 98, 91, -47, 106, -12, -38, 26, -23, 17, -28, -35, 11, -4, -36, -41, -62, 30, 98, -3, 24, 6, -38, -34, 26, 0, -105, -35, 23, 70, 31, 81, 65, -114, 105, -124, 87, -13, 31, -57, -24, 20, 76, -36, -48, -19, 70, 79, 71, 15, 86, 34, 91, -11, 53, 8, -83, -59, -14, -12, -16, 19, 20, 33, 18, -66, -78, -62, -71, 37, -90, 47, -31, 84, 34, 43, -20, -18, -8, -27, -14, 63, 76, -94, 18, 36, -96, -68, -43, 11, 65, -29, -86, 44, 17, -2, 40, -86, -90, 63, -52, -17, -9, 18, 3, -87, -68, 60, 8, -87, 46, -95, 24, -70, -76, 22, -12, 26, -68, -58, -32, 39, -30, -17, -22, -36, -98, 45, -27, -42, 79, -62, 12, 7, -90, -33, -24, 64, -57, -10, 3, 19, -36, 54, 79, -32, 16, -16, 48, 47, -9, 16, 32, -81, -60, 20, 114, 51, -53, 68, -3, -107, 24, -32, 27, 10, -109, -12, 51, 3, 32, -78, -44, 69, -6, 33, -59, -92, 76, -17, -78, 44, -73, 76, -80, 18, 102, 70, -70, -8, -105, 51, -67, -68, -38, 37, -17, -2, 27, 8, -20, 27, 103, -65, -80, 19, -13, -54, -72, -77, 73, -5, -37, 22, -81, 45, -91, 60, 54, -32, 52, -18, -104, 11, 72, 56, 38, -5, -17, 54, -61, 16, -23, 61, -15, -49, -58, -28, -123, -10, -63, -55, 44, -2, 9, -74, 37, -50, -87, -1, -9, 89, -66, -56, 71, 56, -63, -10, 87, -73, -53, 13, 10, -35, -27, -56, -6, -17, -37, 62, -9, -53, -42, -4, 60, -23, 58, 88, -11, 93, 49, 8, 2, 86, -36, 0, 5, 65, 79, 35, -23, -21, 64, 5, 7, -16, 9, -33, -27, 15, 47, 52, -25, -76, -51, 34, 56, -97, -38, -76, -66, 0, 7, 41, -89, -39, -82, 48, -2, 5, -51, 56, 40, 10, 84, -61, 35, 16, 14, 27, 70, 62, -93, -76, 15, 35, 68, -1, 50, -85, -54, 70, 13, -23, 72, 31, 62, -37, 6, -71, -90, 49, -73, -42, -18, -12, -94, 3, 45, -57, 36, 63, 0, -15, -47, -24, -87, 70, -45, 77, -63, 55, -79, -42, -69, -85, -45, -29, -23, 60, -63, -14, -35, 0, -73, 31, -57, 9, 8, 64, 33, -22, 81, -30, 41, 9, -64, 53, -66, 73, -38, 82, 17, 70, -15, 3, -78, -70, 82, -59, 89, 21, 61, 44, 65, -26, -60, -17, -16, -82, -99, -47, -35, 63, 24, -47, 92, -48, 35, -82, -73, -30, -47, -69, -48, 10, -93, -3, 36, 79, -80, 72, 22, 65, -30, -44, -107, 36, -69, 39, 12, -69, -77, -2, 54, -1, -55, 54, 34, 72, -34, -47, -107, -4, 22, 64, 9, 8, -21, 63, 18, -65, -16, 75, 69, -11, 19, 28, -42, 40, 26, 73, -6, 54, -57, -76, -53, -88, -69, 56, 19, -76, 70, 72, 3, 70, -62, 2, -1, 88, -97, -79, 68, -78, 46, -23, -52, -87, -63, 89, 39, -51, -26, -30, -71, 15, -71, -83, 26, 12, 50, -59, -25, -60, 24, -42, 49, -46, -97, -4, 55, -12, -50, -84, -16, 62, -2, -15, 75, 75, 58, 90, -47, -32, 68, 10, -2, -58, -112, 71, -78, 80, 47, -43, -79, 56, 42, -40, 38, 8, -66, -85, -57, 79, 60, 4, -92, 27, -78, -28, 73, -15, -21, -60, 71, -26, -30, 58, -88, -91, 17, 81, -12, -91, -76, -18, 6, 35, 29, 65, -96, 44, 
};
const TfArray<2, int> tensor_dimension3 = { 2, { 3,1024 } };
const TfArray<1, float> quant3_scale = { 1, { 0.00084452203009277582, } };
const TfArray<1, int> quant3_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const ALIGN(16) int32_t tensor_data4[16] = { -483, 2156, -276, 2282, 587, -1198, 2935, -436, -696, 242, -81, 374, 1257, -214, 2293, 1258, };
const TfArray<1, int> tensor_dimension4 = { 1, { 16 } };
const TfArray<16, float> quant4_scale = { 16, { 8.018290827749297e-06, 7.4921708801412024e-06, 7.9678302427055314e-06, 7.0595192482869606e-06, 7.6264000199444126e-06, 7.4943482104572468e-06, 8.0539857663097791e-06, 7.5161092354392167e-06, 7.9350293162860908e-06, 7.75341504777316e-06, 7.4724457590491511e-06, 7.7963750300114043e-06, 7.3463079388602637e-06, 7.1779700192564633e-06, 7.9183846537489444e-06, 8.3580398495541885e-06, } };
const TfArray<16, int> quant4_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&quant4_zero, 0 };
const ALIGN(16) int8_t tensor_data5[16*3*3*8] = { 
  /* [0][0][][] */ 56,65,120,81,-30,-13,6,55, 9,43,18,-22,-82,19,79,-103, 40,70,44,34,-87,-59,57,24, 
  /* [0][1][][] */ 16,71,127,85,81,-29,0,-112, -48,4,52,0,-78,-6,99,-94, -9,103,126,54,125,92,40,-79, 
  /* [0][2][][] */ -84,76,-88,-14,-35,58,97,21, 96,61,10,-44,-99,16,-38,-85, 116,41,65,7,3,-41,124,14, 
  /* [1][0][][] */ -60,104,18,79,-16,-88,-36,57, -79,-35,-47,7,82,115,69,127, 117,39,59,-100,-68,-60,-3,12, 
  /* [1][1][][] */ 38,62,79,-40,-114,-99,115,-35, 24,101,102,46,-32,47,54,-91, 78,42,-20,-75,-46,117,-111,8, 
  /* [1][2][][] */ -68,-36,112,-112,105,85,10,-92, -34,-63,18,-20,46,49,31,-39, -99,-45,101,55,16,-41,-110,-99, 
  /* [2][0][][] */ -30,49,-42,16,-2,-45,15,48, 127,5,91,72,47,-99,9,103, -92,52,53,-63,-29,8,92,-6, 
  /* [2][1][][] */ 86,82,-58,10,-93,31,95,77, -10,100,-11,-55,79,-16,-82,-96, -20,-105,105,21,90,16,-13,-49, 
  /* [2][2][][] */ 28,66,-17,36,-89,71,-96,-55, -76,95,112,114,110,34,84,64, 16,-73,-8,5,-94,-103,-75,-78, 
  /* [3][0][][] */ 64,-72,53,-44,98,-19,-109,82, 30,-127,-34,99,-7,-63,-75,51, -78,11,-59,-40,55,-24,84,72, 
  /* [3][1][][] */ 112,-98,77,-11,-7,-84,-98,-18, -14,-14,-103,-57,-84,47,8,118, -88,48,112,73,-50,-45,99,107, 
  /* [3][2][][] */ 52,25,121,-90,101,-28,49,-39, -125,-42,-30,-48,-75,-101,-23,104, -69,-38,109,-113,79,-48,46,67, 
  /* [4][0][][] */ -51,-54,-59,-60,-116,-95,24,47, -85,-26,-28,-75,-31,69,34,-28, 57,96,100,-55,-105,109,-41,31, 
  /* [4][1][][] */ -105,-36,-4,44,74,77,102,-60, -16,126,13,-11,-96,123,-95,42, -30,-32,39,50,127,-8,96,17, 
  /* [4][2][][] */ -62,-32,-37,30,-16,-63,16,-113, -44,9,-54,37,-12,-39,-48,109, -25,106,-104,-34,118,-27,-87,116, 
  /* [5][0][][] */ -85,58,67,84,-28,-127,-47,111, -84,57,-35,-47,95,87,-90,-44, -70,112,72,46,8,20,-73,69, 
  /* [5][1][][] */ -49,84,-9,-22,69,-20,-46,-112, -90,11,2,51,91,71,99,87, 65,86,-18,94,-105,55,36,1, 
  /* [5][2][][] */ 17,13,-117,55,-116,91,-20,-22, 13,22,-99,54,18,-99,33,-69, 47,32,-78,83,-40,51,-80,-67, 
  /* [6][0][][] */ 109,4,61,81,-99,-9,39,30, 47,-86,80,-91,-29,8,18,75, -24,-120,-48,83,-17,33,-81,-75, 
  /* [6][1][][] */ -56,-22,122,-30,-88,57,-74,-27, 125,4,-77,-98,57,92,28,33, 53,118,107,-63,17,31,98,121, 
  /* [6][2][][] */ 100,-30,86,-74,-75,62,-68,-66, 94,7,-41,-77,85,58,-43,127, -83,-25,97,113,-43,-53,-22,-37, 
  /* [7][0][][] */ -10,99,-12,-116,-93,127,115,54, 68,104,76,107,96,93,57,65, 35,-10,-91,-18,112,39,117,31, 
  /* [7][1][][] */ -8,89,-15,-116,98,-43,62,77, -30,78,18,90,-45,100,86,61, -98,-18,-19,6,-12,-79,-71,108, 
  /* [7][2][][] */ -72,-109,2,27,9,-57,-37,97, -52,-55,6,62,96,13,-94,35, -43,11,25,-8,-93,27,75,45, 
  /* [8][0][][] */ 64,-83,112,70,20,-42,89,55, -32,-52,-72,70,83,-43,-112,97, -11,-51,95,62,16,52,-38,-32, 
  /* [8][1][][] */ 21,-97,127,-10,-1,-125,61,-56, -20,74,12,-2,34,69,-60,44, -92,-84,-71,9,40,67,115,45, 
  /* [8][2][][] */ 15,-84,103,-76,72,62,68,-32, 108,-48,119,-54,78,-87,-57,66, 83,69,-87,18,8,-83,76,-77, 
  /* [9][0][][] */ 32,-53,70,87,-53,86,72,63, -36,-47,-13,-76,-10,63,-36,49, -22,-55,-54,93,-44,53,-52,102, 
  /* [9][1][][] */ -22,124,-69,-92,-81,106,-15,83, -50,-82,107,-100,30,1,-69,-70, -72,59,76,0,-35,68,40,-86, 
  /* [9][2][][] */ -77,127,-37,-28,11,15,-57,19, 3,-24,30,-6,-83,22,-111,82, 0,49,-86,-24,88,85,-64,-36, 
  /* [10][0][][] */ -96,-78,-65,36,33,-52,62,-23, -101,-115,-40,-17,-47,-102,-76,36, -54,-14,-64,58,-71,55,-34,110, 
  /* [10][1][][] */ -14,19,-33,96,14,53,81,79, 112,-123,63,-47,-46,-109,111,97, 48,106,-127,-4,25,25,-78,-47, 
  /* [10][2][][] */ 71,-26,-61,47,59,-95,80,5, -105,49,81,-18,39,105,-103,-49, -92,0,-107,-19,-41,-50,84,-118, 
  /* [11][0][][] */ -117,42,-55,103,82,27,-59,-74, -59,-59,47,14,117,-111,-9,42, -36,-8,-84,73,-94,-103,-86,-35, 
  /* [11][1][][] */ 93,71,56,-89,60,-81,43,-105, -31,27,-96,31,-58,-57,-40,-96, -11,-75,-24,-5,-104,-39,44,-113, 
  /* [11][2][][] */ -63,-76,48,105,79,-24,-80,-41, 17,4,51,26,-40,4,-109,-45, -53,-127,-62,104,-101,9,61,62, 
  /* [12][0][][] */ -89,59,-87,127,-41,-2,105,-11, 62,-20,-83,-48,-101,77,-107,-34, 57,59,91,36,54,-112,-66,74, 
  /* [12][1][][] */ -116,-69,-30,-33,28,69,17,41, 68,-1,-21,-29,29,-80,11,-35, -7,34,92,-10,27,-59,12,100, 
  /* [12][2][][] */ -27,-103,-47,-94,-3,15,-47,19, -69,-56,26,65,17,13,15,-89, 117,-7,99,0,72,-79,-20,-13, 
  /* [13][0][][] */ 15,-18,-33,-57,-121,80,-66,-56, 76,55,-59,3,-125,-105,-66,-96, -56,20,114,-6,88,-100,-87,75, 
  /* [13][1][][] */ -22,9,3,-109,86,-71,15,-5, -44,17,-123,-115,-109,126,75,93, -68,-125,72,-115,62,-14,45,62, 
  /* [13][2][][] */ -22,67,-127,87,-91,13,-126,-76, 25,32,39,-13,88,-42,-90,9, -75,103,-50,-44,-5,18,-35,61, 
  /* [14][0][][] */ 55,17,93,-24,-22,77,13,-60, -12,102,117,29,-1,1,57,-62, 107,-97,28,119,19,-80,5,-78, 
  /* [14][1][][] */ 92,-49,-4,-36,-95,122,2,-64, 109,97,64,46,80,12,105,35, -77,81,-33,-81,-5,43,-103,47, 
  /* [14][2][][] */ -7,72,46,-65,-44,127,-47,-83, -40,-55,-4,-57,106,-83,-11,5, 15,102,39,-59,-15,63,-15,60, 
  /* [15][0][][] */ 65,62,-5,-39,19,-28,-50,81, -9,-22,51,-31,10,-62,20,48, -67,-83,62,-76,-106,-15,16,47, 
  /* [15][1][][] */ 52,-36,60,-48,7,113,-17,64, -7,-63,77,-14,-94,98,23,94, 76,-1,101,-76,59,57,-58,-36, 
  /* [15][2][][] */ -49,-7,-41,-68,-73,-90,82,127, 18,16,91,102,5,-77,-42,-7, 116,22,112,-53,-109,5,-59,86, 
};
const TfArray<4, int> tensor_dimension5 = { 4, { 16,3,3,8 } };
const TfArray<16, float> quant5_scale = { 16, { 0.0014576739631593227, 0.0013620287645608187, 0.0014485005522146821, 0.0012833754299208522, 0.0013864306965842843, 0.0013624245766550303, 0.0014641630696132779, 0.0013663806021213531, 0.0014425375266000628, 0.0014095212100073695, 0.0013584428234025836, 0.0014173311647027731, 0.0013355117989704013, 0.001304909004829824, 0.0014395116595551372, 0.001519438112154603, } };
const TfArray<16, int> quant5_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const ALIGN(16) int32_t tensor_data6[8] = { 2270, 88, 2605, -3161, -504, 494, -160, 680, };
const TfArray<1, int> tensor_dimension6 = { 1, { 8 } };
const TfArray<8, float> quant6_scale = { 8, { 7.3340111157449428e-06, 7.7850554589531384e-06, 7.6897367762285285e-06, 7.9790979725657962e-06, 7.0977816903905477e-06, 7.6897249527974054e-06, 7.4504978329059668e-06, 7.1812414716987405e-06, } };
const TfArray<8, int> quant6_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[8*3*3*3] = { 
  /* [0][0][][] */ 3,71,4, 30,-121,-27, 85,-46,-77, 
  /* [0][1][][] */ -38,39,-109, 105,-99,-114, 38,-15,-44, 
  /* [0][2][][] */ -31,-127,44, -9,47,76, 64,-4,8, 
  /* [1][0][][] */ -123,-106,-24, 93,-122,101, -100,113,-1, 
  /* [1][1][][] */ -7,-39,-71, 89,-99,119, 36,-114,-50, 
  /* [1][2][][] */ 127,116,59, -64,43,30, 30,-77,-102, 
  /* [2][0][][] */ 80,117,-105, -35,-107,-106, 61,69,-62, 
  /* [2][1][][] */ 28,55,-95, 63,-121,-72, 81,75,-76, 
  /* [2][2][][] */ 97,48,127, -1,0,17, 46,-91,-90, 
  /* [3][0][][] */ -109,-25,-14, -127,93,-72, 99,0,94, 
  /* [3][1][][] */ -121,-17,-99, -27,29,28, -15,116,32, 
  /* [3][2][][] */ 42,16,54, 84,84,97, 38,96,101, 
  /* [4][0][][] */ 107,-70,-25, 127,-92,17, 4,112,-22, 
  /* [4][1][][] */ -14,-114,76, 62,78,-36, 114,-82,-86, 
  /* [4][2][][] */ -68,-86,-53, -101,-98,-15, -111,-30,-24, 
  /* [5][0][][] */ -36,27,-6, 55,58,23, -72,10,-11, 
  /* [5][1][][] */ 91,-42,116, 22,72,-36, 10,-109,36, 
  /* [5][2][][] */ -1,102,-47, -20,109,-127, -21,-123,19, 
  /* [6][0][][] */ 64,118,-15, 36,-29,-41, -73,-95,-127, 
  /* [6][1][][] */ -125,-79,8, -73,-56,6, -48,-64,101, 
  /* [6][2][][] */ 19,-15,-47, 55,-15,38, -50,-9,119, 
  /* [7][0][][] */ 99,3,71, 45,105,39, -100,82,-40, 
  /* [7][1][][] */ -67,117,-125, 75,-118,-45, 33,-16,127, 
  /* [7][2][][] */ -53,-14,-41, 46,-111,-32, 88,-29,-10, 
};
const TfArray<4, int> tensor_dimension7 = { 4, { 8,3,3,3 } };
const TfArray<8, float> quant7_scale = { 8, { 0.0018701726803556085, 0.001985189039260149, 0.0019608826842159033, 0.0020346699748188257, 0.001809934270568192, 0.0019608796574175358, 0.0018998768646270037, 0.0018312165047973394, } };
const TfArray<8, int> quant7_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const TfArray<4, int> tensor_dimension8 = { 4, { 1,32,32,8 } };
const TfArray<1, float> quant8_scale = { 1, { 0.0055007436312735081, } };
const TfArray<1, int> quant8_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const TfArray<4, int> tensor_dimension9 = { 4, { 1,16,16,8 } };
const TfArray<1, float> quant9_scale = { 1, { 0.0055007436312735081, } };
const TfArray<1, int> quant9_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const TfArray<4, int> tensor_dimension10 = { 4, { 1,16,16,16 } };
const TfArray<1, float> quant10_scale = { 1, { 0.0029774489812552929, } };
const TfArray<1, int> quant10_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const TfArray<4, int> tensor_dimension11 = { 4, { 1,8,8,16 } };
const TfArray<1, float> quant11_scale = { 1, { 0.0029774489812552929, } };
const TfArray<1, int> quant11_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<2, int> tensor_dimension12 = { 2, { 1,1024 } };
const TfArray<1, float> quant12_scale = { 1, { 0.0029774489812552929, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<2, int> tensor_dimension13 = { 2, { 1,3 } };
const TfArray<1, float> quant13_scale = { 1, { 0.0029587291646748781, } };
const TfArray<1, int> quant13_zero = { 1, { 64 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<2, int> tensor_dimension14 = { 2, { 1,3 } };
const TfArray<1, float> quant14_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfLiteConvParams opdata0 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs0 = { 3, { 0,7,6 } };
const TfArray<1, int> outputs0 = { 1, { 8 } };
const TfLitePoolParams opdata1 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs1 = { 1, { 8 } };
const TfArray<1, int> outputs1 = { 1, { 9 } };
const TfLiteConvParams opdata2 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs2 = { 3, { 9,5,4 } };
const TfArray<1, int> outputs2 = { 1, { 10 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 2,2, 2,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 10 } };
const TfArray<1, int> outputs3 = { 1, { 11 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 11,1 } };
const TfArray<1, int> outputs4 = { 1, { 12 } };
const TfLiteFullyConnectedParams opdata5 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs5 = { 3, { 12,3,2 } };
const TfArray<1, int> outputs5 = { 1, { 13 } };
const TfLiteSoftmaxParams opdata6 = { 1 };
const TfArray<1, int> inputs6 = { 1, { 13 } };
const TfArray<1, int> outputs6 = { 1, { 14 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 8192, (TfLiteIntArray*)&tensor_dimension0, 3072, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 12, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant2))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 3072, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant3))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant4))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 1152, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant5))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant6))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 216, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant7))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension8, 8192, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 8192, (TfLiteIntArray*)&tensor_dimension9, 2048, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension10, 4096, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 4096, (TfLiteIntArray*)&tensor_dimension11, 1024, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension12, 1024, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 1024, (TfLiteIntArray*)&tensor_dimension13, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension14, 3, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_SOFTMAX, },
};

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  };
  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }
  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }

  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }
  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }
  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }
};

} // namespace

TfLiteStatus tflite_learn_26_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  ctx.impl_ = static_cast<void*>(&micro_context_);
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;
  ctx.tensors_size = 15;
  for (size_t i = 0; i < 15; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 7; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 7; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      ResetTensors();

      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteStatus tflite_learn_26_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(inTensorIndices[index], tensor);
  return kTfLiteOk;
}

static const int outTensorIndices[] = {
  14, 
};
TfLiteStatus tflite_learn_26_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(outTensorIndices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_26_invoke() {
  for (size_t i = 0; i < 7; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_26_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
